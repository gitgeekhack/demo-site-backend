{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"CustomYolov5ModelTraining.ipynb","provenance":[{"file_id":"16aBMBO8_J0j6u1SLJTx_ywT5DUeeiO52","timestamp":1644902813326}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"GD9gUQpaBxNa"},"source":["###  **Custom YOLOV5 Model training**\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"7mGmQbAO5pQb"},"source":["#Install Dependencies\n","\n","_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_"]},{"cell_type":"code","metadata":{"id":"Ie5uLDH4uzAp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647341624638,"user_tz":-330,"elapsed":2217,"user":{"displayName":"Data Science","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01815115652333822180"}},"outputId":"05eec3cc-79d3-42b8-8685-165b657346a3"},"source":["# clone YOLOv5 repository\n","!git clone https://github.com/ultralytics/yolov5  # clone repo\n","%cd yolov5"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 11301, done.\u001b[K\n","remote: Total 11301 (delta 0), reused 0 (delta 0), pack-reused 11301\u001b[K\n","Receiving objects: 100% (11301/11301), 11.20 MiB | 25.44 MiB/s, done.\n","Resolving deltas: 100% (7814/7814), done.\n","/content/yolov5\n"]}]},{"cell_type":"code","metadata":{"id":"zvc8jlQ9Kyvb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647341658839,"user_tz":-330,"elapsed":26023,"user":{"displayName":"Data Science","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01815115652333822180"}},"outputId":"0e548169-06a7-4e89-f4ee-00eee16fafbc"},"source":["# To mount your Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"epFXv6Gg-ydD","collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647341662381,"user_tz":-330,"elapsed":402,"user":{"displayName":"Data Science","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01815115652333822180"}},"outputId":"0bd09299-9383-400d-b5b8-ee13d11c3812"},"source":["# !unzip (yourzipfolder).zip -d \"/content/\" (path where to extract)\n","!unzip \"/content/drive/MyDrive/veronica/test_new.zip\" -d \"/content/\""],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["unzip:  cannot find or open /content/drive/MyDrive/veronica/test_new.zip, /content/drive/MyDrive/veronica/test_new.zip.zip or /content/drive/MyDrive/veronica/test_new.zip.ZIP.\n"]}]},{"cell_type":"code","metadata":{"id":"wbvMlHd_QwMG"},"source":["# install dependencies as necessary\n","!pip install -qr requirements.txt  # install dependencies (ignore errors)\n","import torch\n","\n","from IPython.display import Image, clear_output  # to display images\n","from utils.downloads import gdrive_download  # to download models/datasets\n","\n","# clear_output()\n","print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZZ3DmmGQztJj"},"source":["# this is the YAML file that we're loading into this notebook with our data\n","%cat data.yaml #path to your data.yaml file"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UwJx-2NHsYxT"},"source":["# Define Model Configuration and Architecture\n","\n","We will write a yaml script that defines the parameters for our model like the number of classes, anchors, and each layer.\n"]},{"cell_type":"code","metadata":{"id":"dOPn9wjOAwwK"},"source":["# define number of classes based on YAML\n","import yaml\n","with open(\"data.yaml\", 'r') as stream: #path to your data.yaml file\n","    num_classes = str(yaml.safe_load(stream)['nc'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Rvt5wilnDyX"},"source":["#Yolov5 model configuration\n","%cat /content/yolov5/models/yolov5l.yaml"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t14hhyqdmw6O"},"source":["#customize iPython writefile so we can write variables\n","from IPython.core.magic import register_line_cell_magic\n","\n","@register_line_cell_magic\n","def writetemplate(line, cell):\n","    with open(line, 'w') as f:\n","        f.write(cell.format(**globals()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uDxebz13RdRA"},"source":["%%writetemplate /content/yolov5/models/DLnewdata.yaml\n","\n","# parameters\n","nc: {num_classes}  # number of classes\n","depth_multiple: 0.33  # model depth multiple\n","width_multiple: 0.50  # layer channel multiple\n","\n","# anchors\n","anchors:\n","  - [10,13, 16,30, 33,23]  # P3/8\n","  - [30,61, 62,45, 59,119]  # P4/16\n","  - [116,90, 156,198, 373,326]  # P5/32\n","\n","# YOLOv5 backbone\n","backbone:\n","  # [from, number, module, args]\n","  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n","   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n","   [-1, 3, BottleneckCSP, [128]],\n","   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n","   [-1, 9, BottleneckCSP, [256]],\n","   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n","   [-1, 9, BottleneckCSP, [512]],\n","   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n","   [-1, 1, SPP, [1024, [5, 9, 13]]],\n","   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n","  ]\n","\n","# YOLOv5 head\n","head:\n","  [[-1, 1, Conv, [512, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n","   [-1, 3, BottleneckCSP, [512, False]],  # 13\n","\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n","   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n","\n","   [-1, 1, Conv, [256, 3, 2]],\n","   [[-1, 14], 1, Concat, [1]],  # cat head P4\n","   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n","\n","   [-1, 1, Conv, [512, 3, 2]],\n","   [[-1, 10], 1, Concat, [1]],  # cat head P5\n","   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n","\n","   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n","  ]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Augmentation\n","\n","If you require to augment the input dataset, you can use the Albumentation library integrated in yolov5. \n","By editing yolov5/utils/augmentations.py\n","Ref: https://github.com/albumentations-team/albumentations/issues/949#issue-937230240"],"metadata":{"id":"l9QWGOrhz3dp"}},{"cell_type":"code","metadata":{"id":"tlU-QeK5HAi1"},"source":["pip install -U albumentations"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model Training"],"metadata":{"id":"x-oLF_9o0irC"}},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"7d_jdX9AIHWp"},"source":["## !python train.py --img (input dimensions) --batch (batch size) --epochs (no of iterations/epochs) --data (path to your data.yaml) --cfg (path to your Yolov5 model configuration file) --weights yolov5l.pt (yolo version weights) --device 0 (GPU/CPU configurations)\n","\n","%%time\n","%cd /content/yolov5/\n","!python train.py --img 640 --batch 4 --epochs 300 --data '../data.yaml' --cfg /content/yolov5/models/DLnewdata.yaml --weights yolov5l.pt --device 0 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bOy5KI2ncnWd"},"source":["# Start tensorboard\n","# Launch after you have started training\n","# logs save in the folder \"runs\"\n","%load_ext tensorboard\n","%tensorboard --logdir runs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C60XAsyv6OPe"},"source":["# we can also output some older school graphs if the tensor board isn't working for whatever reason... \n","from utils.plots import plot_results  # plot results.txt as results.png\n","Image(filename='/content/yolov5/runs/train/exp/results.png', width=1000)  # view results.png"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DLI1JmHU7B0l"},"source":["### Data Visualisation\n","\n","After training starts, view `train*.jpg` images to see training images, labels and augmentation effects.\n","\n","Note a mosaic dataloader is used for training (shown below), a new dataloading concept developed by Glenn Jocher."]},{"cell_type":"code","metadata":{"id":"PF9MLHDb7tB6"},"source":["# first, display our ground truth data\n","\n","print(\"GROUND TRUTH TRAINING DATA:\")\n","Image(filename='/content/yolov5/runs/train/exp/test_batch0_labels.jpg', width=900)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W40tI99_7BcH"},"source":["# print out an augmented training example\n","print(\"GROUND TRUTH AUGMENTED TRAINING DATA:\")\n","Image(filename='/content/yolov5/runs/train/exp/train_batch0.jpg', width=900)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yIEwt5YLeQ7P"},"source":["# trained weights are saved by default in our weights folder\n","%ls runs/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4SyOWS80qR32"},"source":["%ls runs/train/exp4/weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9nmZZnWOgJ2S"},"source":["# use the best weights!\n","%cd /content/yolov5/\n","!python detect.py --weights runs/train/exp/weights/best.pt --img 640 --conf 0.7 --source ../Train/test/images --augment"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"odKEqYtTgbRc"},"source":["#display inference on ALL test images\n","#this looks much better with longer training above\n","\n","import glob\n","from IPython.display import Image, display\n","\n","for imageName in glob.glob('/content/DLyolov5newannot/runs/detect/exp/*.jpg'): #assuming JPG\n","    display(Image(filename=imageName))\n","    print(\"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### save your model to Google drive"],"metadata":{"id":"oBZ0FCyp1Kco"}},{"cell_type":"code","metadata":{"id":"VRcjlolko3JB"},"source":["## %cp (your best model path --source) (specify target saving to drive)\n","%cp /content/yolov5/runs/train/exp/weights/best.pt /content/drive/MyDrive/"],"execution_count":null,"outputs":[]}]}